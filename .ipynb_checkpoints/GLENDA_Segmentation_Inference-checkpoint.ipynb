{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import glob\n",
    "import shutil\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(f'GPU device availability: {physical_devices}')\n",
    "\n",
    "outer_dim = 3\n",
    "num_classes = 10\n",
    "img_size = [512, 960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_dataset_raw, val_dataset_raw), dataset_info = tfds.load(\n",
    "    \"glenda_coco2:4.0.0\", split=[\"train[:95%]\", \"train[95%:]\"], with_info=True,\n",
    "    shuffle_files=True, data_dir=\"C:\\\\Users\\\\Students\\\\tensorflow_datasets\"\n",
    ")\n",
    "\n",
    "num_samples = dataset_info.splits['train'].num_examples\n",
    "print(f\"Total number samples in GLENDA dataset: {num_samples}\")\n",
    "print(dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17664611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_moments(x, axes=[0, 1], epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(x, axes=axes)\n",
    "    x_normed = (x - mean) / tf.sqrt(variance + epsilon) # epsilon to avoid dividing by zero\n",
    "    return x_normed\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    seg_data = tf.cast(sample['segmentation'], dtype=tf.float32)\n",
    "    img_data = tf.cast(sample['image'], dtype=tf.float32)\n",
    "    img_data = tf.image.resize(img_data, img_size)\n",
    "    seg_data = tf.image.resize(seg_data, img_size)\n",
    "\n",
    "    neg_updates = tf.tile([0], [tf.reduce_sum(tf.cast(seg_data < 0.5, dtype=tf.int32))])\n",
    "    pos_updates = tf.tile([1], [tf.reduce_sum(tf.cast(seg_data >= 0.5, dtype=tf.int32))])\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data >= 0.5), tf.cast(pos_updates, dtype=tf.float32))\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data < 0.5), tf.cast(neg_updates, dtype=tf.float32))\n",
    "\n",
    "    return normalize_with_moments(img_data), seg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#                Soft Dice coefficient                #\n",
    "#-----------------------------------------------------#\n",
    "def dice_soft(y_true, y_pred, smooth=0.00001):\n",
    "    \"\"\"Dice loss originates from Sørensen–Dice coefficient, which is a statistic developed in 1940s to gauge the similarity between two samples.\n",
    "    Variant: Classwise score calculation\n",
    "    Credits documentation: https://github.com/mlyg\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    # Identify axis\n",
    "    axis = identify_axis(y_true.get_shape())\n",
    "\n",
    "    # Calculate required variables\n",
    "    intersection = y_true * y_pred\n",
    "    intersection = K.sum(intersection, axis=axis)\n",
    "    y_true = K.sum(y_true, axis=axis)\n",
    "    y_pred = K.sum(y_pred, axis=axis)\n",
    "\n",
    "    # Calculate Soft Dice Similarity Coefficient\n",
    "    dice = ((2 * intersection) + smooth) / (y_true + y_pred + smooth)\n",
    "\n",
    "    # Obtain mean of Dice & return result score\n",
    "    dice = K.mean(dice)\n",
    "    return dice\n",
    "    \n",
    "#-----------------------------------------------------#\n",
    "#                    Tversky loss                     #\n",
    "#-----------------------------------------------------#\n",
    "#                     Reference:                      #\n",
    "#                Sadegh et al. (2017)                 #\n",
    "#     Tversky loss function for image segmentation    #\n",
    "#      using 3D fully convolutional deep networks     #\n",
    "#-----------------------------------------------------#\n",
    "# alpha=beta=0.5 : dice coefficient                   #\n",
    "# alpha=beta=1   : jaccard                            #\n",
    "# alpha+beta=1   : produces set of F*-scores          #\n",
    "#-----------------------------------------------------#\n",
    "def tversky_class(y_true, y_pred, smooth=0.000001):\n",
    "     # Define alpha and beta\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    # Calculate Tversky for each class\n",
    "    axis = identify_axis(y_true.get_shape())\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = K.sum(y_true * y_pred, axis=axis)\n",
    "    fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "    fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "    tversky_class = (tp + smooth)/(tp + alpha*fn + beta*fp + smooth)\n",
    "\n",
    "    return tversky_class\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=0.000001):\n",
    "    # Sum up classes to one score\n",
    "    tversky = K.mean(tversky_class(y_true, y_pred, smooth))\n",
    "    # Return Tversky\n",
    "    return tversky\n",
    "\n",
    "def tversky_loss(y_true, y_pred, smooth=0.000001):\n",
    "    # Sum up classes to one score\n",
    "    tversky = K.sum(tversky_class(y_true, y_pred, smooth), axis=[-1])\n",
    "    # Identify number of classes\n",
    "    n = K.cast(K.shape(y_true)[-1], 'float32')\n",
    "    # Return Tversky\n",
    "    return n-tversky\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#             Tversky & Crossentropy loss             #\n",
    "#-----------------------------------------------------#\n",
    "def tversky_crossentropy(y_truth, y_pred):\n",
    "    # Obtain Tversky Loss\n",
    "    tversky = focal_tversky_loss(y_truth, y_pred)\n",
    "    # Obtain Crossentropy\n",
    "    crossentropy = K.binary_crossentropy(y_truth, y_pred)\n",
    "    crossentropy = K.mean(crossentropy)\n",
    "    # Return sum\n",
    "    return tversky + crossentropy\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, delta=0.7, gamma=0.75, smooth=0.000001):\n",
    "    # Clip values to prevent division by zero error\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    axis = identify_axis(y_true.get_shape())\n",
    "    # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "    tp = K.sum(y_true * y_pred, axis=axis)\n",
    "    fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "    fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "    tversky_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "    # Average class scores\n",
    "    return K.mean(K.pow((1-tversky_class), gamma))\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#                     Subroutines                     #\n",
    "#-----------------------------------------------------#\n",
    "# Identify shape of tensor and return correct axes\n",
    "def identify_axis(shape):\n",
    "    if len(shape) == 5 : return [1,2,3]\n",
    "    elif len(shape) == 4 : return [1,2]\n",
    "    # Exception - Unknown\n",
    "    else:\n",
    "        print(shape) \n",
    "        raise ValueError('Metric: Shape of tensor is neither 2D or 3D.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class Plain:\n",
    "    #---------------------------------------------#\n",
    "    #                Initialization               #\n",
    "    #---------------------------------------------#\n",
    "    def __init__(self, activation='sigmoid', conv_layer_activation='lrelu',\n",
    "                 batch_normalization=True, batch_normalization_params=None,\n",
    "                 dropout=0, pooling=(1, 2, 2)):\n",
    "        # Parse parameter\n",
    "        if batch_normalization_params is None:\n",
    "            batch_normalization_params = {'epsilon': 1e-5}\n",
    "        self.activation = activation\n",
    "        # Parse activation layer\n",
    "        if conv_layer_activation == \"lrelu\":\n",
    "            self.conv_layer_activation = LeakyReLU(alpha=0.1)\n",
    "        # Batch normalization settings\n",
    "        self.ba_norm = batch_normalization\n",
    "        self.ba_norm_params = batch_normalization_params\n",
    "        # Dropout params\n",
    "        self.dropout = dropout\n",
    "        # Adjust pooling step\n",
    "        self.pooling = pooling\n",
    "        # Create list of filters\n",
    "        self.feature_map = [30, 60, 120, 240, 320]\n",
    "        \n",
    "    def create_model(self, n_labels):\n",
    "        # Input layer\n",
    "        inputs = Input(img_size + [outer_dim])\n",
    "        # Start the CNN Model chain with adding the inputs as first tensor\n",
    "        cnn_chain = inputs\n",
    "        # Cache contracting normalized conv layers\n",
    "        # for later copy & concatenate links\n",
    "        contracting_convs = []\n",
    "\n",
    "        # Contracting layers\n",
    "        for i in range(0, len(self.feature_map)):\n",
    "            neurons = self.feature_map[i]\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "            contracting_convs.append(cnn_chain)\n",
    "            cnn_chain = MaxPooling2D(pool_size=(2, 2))(cnn_chain)\n",
    "\n",
    "        # Middle Layer\n",
    "        neurons = self.feature_map[-1]\n",
    "        cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                  self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "        cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                  self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "\n",
    "        # Expanding Layers\n",
    "        for i in reversed(range(0, len(self.feature_map))):\n",
    "            neurons = self.feature_map[i]\n",
    "            cnn_chain = Conv2DTranspose(neurons, (2, 2), strides=(2, 2),\n",
    "                                        padding='same')(cnn_chain)\n",
    "            cnn_chain = concatenate([cnn_chain, contracting_convs[i]], axis=-1)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "\n",
    "        # Output Layer\n",
    "        conv_out = Conv2D(n_labels, (1, 1), activation=self.activation)(cnn_chain)\n",
    "        # Create Model with associated input and output layers\n",
    "        model = Model(inputs=[inputs], outputs=[conv_out])\n",
    "        # Return model\n",
    "        return model\n",
    "\n",
    "# ----------------------------------------------------#\n",
    "#                   Subroutines 2D                    #\n",
    "# ----------------------------------------------------#\n",
    "# Convolution layer\n",
    "def conv_layer_2D(input, neurons, activation, ba_norm, ba_params, dropout, strides=1):\n",
    "    conv = Conv2D(neurons, (3, 3), padding='same', strides=strides)(input)\n",
    "\n",
    "    if dropout:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "    if ba_norm:\n",
    "        conv = tfa.layers.InstanceNormalization(**ba_params)(conv)\n",
    "\n",
    "    return activation(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e252e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Plain().create_model(num_classes)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=5e-4)\n",
    "model.compile(loss=tversky_crossentropy, optimizer=optimizer, metrics=[dice_soft])\n",
    "\n",
    "latest_checkpoint = tf.train.latest_checkpoint(\"C:\\\\Users\\\\Students\\\\Desktop\\\\Endometriosis\\\\Notebooks\\\\glenda_model\")\n",
    "model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=10) # controls default text sizes\n",
    "\n",
    "def visualize_detections(image, boxes, classes, title, figsize=(17, 17), linewidth=1, color=[1, 1, 1]):\n",
    "    \"\"\"Visualize Detections\"\"\"\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    for box, _cls in zip(boxes, classes):\n",
    "        _cls_parts = _cls.split('.')\n",
    "        text = f\"{_cls_parts[0][:2].lower()}.{_cls_parts[1][:3].lower()}\"\n",
    "        \n",
    "        y1, x1, y2, x2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        \n",
    "        patch = plt.Rectangle(\n",
    "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "        ax.text(\n",
    "            (x1 + x2) // 2,\n",
    "            y2 - 10,\n",
    "            text,\n",
    "            bbox={\"facecolor\": color, \"alpha\": 0.4},\n",
    "            clip_box=ax.clipbox,\n",
    "            clip_on=True,\n",
    "        )\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "def dice_soft_np(y_true, y_pred, smooth=0.00001):\n",
    "    axis = (0, 1)\n",
    "\n",
    "    # Calculate required variables\n",
    "    intersection = np.multiply(y_true, y_pred)\n",
    "    intersection = np.sum(intersection, axis=axis)\n",
    "    y_true = np.sum(y_true, axis=axis)\n",
    "    y_pred = np.sum(y_pred, axis=axis)\n",
    "\n",
    "    # Calculate Soft Dice Similarity Coefficient\n",
    "    dice = np.divide((2 * intersection) + smooth, y_true + y_pred + smooth)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66d2a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cat_names = ['Adhesions.Dense', 'Adhesions.Filmy', 'Deep.Endometriosis', 'Ovarian.Chocolate Fluid', \n",
    "             'Ovarian.Endometrioma', 'Superficial.Black', 'Superficial.Red', 'Superficial.Subtle', \n",
    "             'Superficial.White', 'Background']\n",
    "\n",
    "all_dice_scores = []\n",
    "all_y_true, all_y_pred = [], []\n",
    "\n",
    "for k, sample in enumerate(val_dataset_raw):\n",
    "    img_data_orig = sample['image']\n",
    "    seg_data_orig = sample['segmentation']\n",
    "    \n",
    "    seg_data = tf.cast(seg_data_orig, dtype=tf.float32)\n",
    "    img_data = tf.cast(img_data_orig, dtype=tf.float32)\n",
    "    img_data = tf.image.resize(img_data, img_size)\n",
    "    seg_data = tf.image.resize(seg_data, img_size)\n",
    "\n",
    "    neg_updates = tf.tile([0], [tf.reduce_sum(tf.cast(seg_data < 0.5, dtype=tf.int32))])\n",
    "    pos_updates = tf.tile([1], [tf.reduce_sum(tf.cast(seg_data >= 0.5, dtype=tf.int32))])\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data >= 0.5), tf.cast(pos_updates, dtype=tf.float32))\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data < 0.5), tf.cast(neg_updates, dtype=tf.float32))\n",
    "        \n",
    "    pred_data = model.predict(normalize_with_moments(tf.expand_dims(img_data, 0)))\n",
    "    prediction = np.where(pred_data > 0.9, 1, 0)[0]\n",
    "    \n",
    "    y_true = tf.reduce_max(seg_data, axis=[0,1]).numpy().astype(int)\n",
    "    y_pred = np.zeros((num_classes,), dtype=int)\n",
    "    \n",
    "    all_dice_scores.append(dice_soft_np(seg_data.numpy(), prediction))\n",
    "    all_y_true.append(y_true)\n",
    "    all_y_pred.append(y_pred)\n",
    "    \n",
    "    prediction_classes, prediction_boxes = [], []\n",
    "    gt_classes, gt_boxes = [], []\n",
    "    \n",
    "    for i in range(num_classes-1):\n",
    "        ground_truth = label(seg_data_orig[...,i])\n",
    "        prediction_cls = label(prediction[...,i]) \n",
    "        props_prediction = [p for p  in regionprops(prediction_cls) if p.area > 100]\n",
    "        props_gt = [p for p in regionprops(ground_truth)]\n",
    "        \n",
    "        prediction_boxes.extend([p.bbox for p in props_prediction])\n",
    "        gt_boxes.extend([p.bbox for p in props_gt])\n",
    "        \n",
    "        prediction_classes.extend([cat_names[i]] * len(props_prediction))\n",
    "        gt_classes.extend([cat_names[i]] * len(props_gt))\n",
    "        \n",
    "        if prediction_boxes:\n",
    "            y_pred[i] = 1\n",
    "    \n",
    "    if k < 100:\n",
    "        visualize_detections(img_data_orig, gt_boxes, gt_classes, \"Ground Thruth\")\n",
    "        visualize_detections(img_data, prediction_boxes, prediction_classes, \"Model Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete DSC\")\n",
    "print(list(zip(cat_names, np.array(all_dice_scores).mean(axis=0))))\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(classification_report(np.array(all_y_true), np.array(all_y_pred), target_names=cat_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "############################################################\n",
    "#  COCO Evaluation\n",
    "############################################################\n",
    "def evaluate_coco(model, dataset, coco, eval_type=\"bbox\"):\n",
    "    results, coco_image_ids = [], []\n",
    "    \n",
    "    for sample in tqdm(dataset):\n",
    "        img_id = sample[\"id\"].numpy().decode('utf-8')\n",
    "        img_data_orig = sample['image']\n",
    "        seg_data_orig = sample['segmentation']\n",
    "        img_data_orig_shape = tf.shape(img_data_orig).numpy()\n",
    "\n",
    "        seg_data = tf.cast(seg_data_orig, dtype=tf.float32)\n",
    "        img_data = tf.cast(img_data_orig, dtype=tf.float32)\n",
    "        img_data = tf.image.resize(img_data, img_size)\n",
    "        seg_data = tf.image.resize(seg_data, img_size)\n",
    "\n",
    "        pred_data = model.predict(normalize_with_moments(tf.expand_dims(img_data, 0)))\n",
    "        prediction = np.where(pred_data > 0.9, 1, 0)[0]\n",
    "        prediction_classes, prediction_boxes = [], []\n",
    "\n",
    "        for i in range(num_classes-1):\n",
    "            prediction_cls = label(prediction[...,i]) \n",
    "            props_prediction = [p for p  in regionprops(prediction_cls) if p.area > 100]\n",
    "            props_gt = [p for p in regionprops(ground_truth)]\n",
    "\n",
    "            prediction_boxes.extend([p.bbox for p in props_prediction])\n",
    "            prediction_classes.extend([i * len(props_prediction)])        \n",
    "        \n",
    "        ratio = (img_size[0] / img_data_orig_shape[0], img_size[1] / img_data_orig_shape[1])\n",
    "        coco_image_ids.append(img_id)\n",
    "        \n",
    "        for _cls, bbox in zip(prediction_classes, prediction_boxes):\n",
    "            y1, x1, y2, x2 = bbox\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "                                       \n",
    "            results.append({\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": _cls,\n",
    "                \"bbox\": [int(x1 / ratio[1]), int(y1 / ratio[0]), int(w / ratio[1]), int(h / ratio[0])],\n",
    "                \"score\": 1.0\n",
    "            })\n",
    "\n",
    "    # Load results. This modifies results with additional attributes.\n",
    "    coco_results = coco.loadRes(results)\n",
    "\n",
    "    # Evaluate\n",
    "    cocoEval = COCOeval(coco, coco_results, eval_type)\n",
    "    cocoEval.params.imgIds = coco_image_ids\n",
    "    cocoEval.params.iouThrs = np.linspace(.1, 0.95, int(np.round((0.95 - .1) / .05)) + 1, endpoint=True)\n",
    "    cocoEval.params.maxDets = [1, 2, 5]\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    \n",
    "    return cocoEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f64e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_common = \"C:\\\\Users\\\\Students\\\\Desktop\\\\Endometriosis\\\\Datasets\"\n",
    "\n",
    "coco_path = os.path.join(path_common, 'glenda_coco2', 'glenda_full_v3.json')\n",
    "coco_annotation = COCO(annotation_file=coco_path)\n",
    "\n",
    "coco_eval = evaluate_coco(model, val_dataset_raw, coco_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe12fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
