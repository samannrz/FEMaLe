{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f115e7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device availability: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import glob\n",
    "import shutil\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(f'GPU device availability: {physical_devices}')\n",
    "\n",
    "outer_dim = 3\n",
    "num_classes = 10\n",
    "img_size = [512, 960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d0b4ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset glenda_coco2 not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- asset\n\t- assin2\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mslr_web\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_rwrl\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- sentiment140\n\t- shapes3d\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_nlg\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_xnli\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: glenda_coco2 -> ref_coco\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-91feab13a611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m (train_dataset_raw, val_dataset_raw), dataset_info = tfds.load(\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"glenda_coco2:4.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train[:95%]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train[95%:]\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\Students\\\\tensorflow_datasets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mbuilder_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m   \u001b[0mdbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_gcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_gcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;31m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mnot_found_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;31m# First check whether code exists or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Class not found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0m_reraise_with_list_builders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=bad-return-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36m_reraise_with_list_builders\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0merror_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf'\\nDid you mean: {name} -> {close_matches[0]}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     95\u001b[0m             f'Cannot load {ds_name} when community datasets are disabled')\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimported_builder_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenvs/endtensorenv/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mimported_builder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dataset {name} not found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mbuilder_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset glenda_coco2 not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- asset\n\t- assin2\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mslr_web\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_rwrl\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- sentiment140\n\t- shapes3d\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_nlg\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_xnli\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: glenda_coco2 -> ref_coco\n"
     ]
    }
   ],
   "source": [
    "(train_dataset_raw, val_dataset_raw), dataset_info = tfds.load(\n",
    "    \"glenda_coco2:4.0.0\", split=[\"train[:95%]\", \"train[95%:]\"], with_info=True,\n",
    "    shuffle_files=True, data_dir=\"C:\\\\Users\\\\Students\\\\tensorflow_datasets\"\n",
    ")\n",
    "\n",
    "num_samples = dataset_info.splits['train'].num_examples\n",
    "print(f\"Total number samples in GLENDA dataset: {num_samples}\")\n",
    "print(dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17664611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_moments(x, axes=[0, 1], epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(x, axes=axes)\n",
    "    x_normed = (x - mean) / tf.sqrt(variance + epsilon) # epsilon to avoid dividing by zero\n",
    "    return x_normed\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    seg_data = tf.cast(sample['segmentation'], dtype=tf.float32)\n",
    "    img_data = tf.cast(sample['image'], dtype=tf.float32)\n",
    "    img_data = tf.image.resize(img_data, img_size)\n",
    "    seg_data = tf.image.resize(seg_data, img_size)\n",
    "\n",
    "    neg_updates = tf.tile([0], [tf.reduce_sum(tf.cast(seg_data < 0.5, dtype=tf.int32))])\n",
    "    pos_updates = tf.tile([1], [tf.reduce_sum(tf.cast(seg_data >= 0.5, dtype=tf.int32))])\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data >= 0.5), tf.cast(pos_updates, dtype=tf.float32))\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data < 0.5), tf.cast(neg_updates, dtype=tf.float32))\n",
    "\n",
    "    return normalize_with_moments(img_data), seg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#                Soft Dice coefficient                #\n",
    "#-----------------------------------------------------#\n",
    "def dice_soft(y_true, y_pred, smooth=0.00001):\n",
    "    \"\"\"Dice loss originates from Sørensen–Dice coefficient, which is a statistic developed in 1940s to gauge the similarity between two samples.\n",
    "    Variant: Classwise score calculation\n",
    "    Credits documentation: https://github.com/mlyg\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    # Identify axis\n",
    "    axis = identify_axis(y_true.get_shape())\n",
    "\n",
    "    # Calculate required variables\n",
    "    intersection = y_true * y_pred\n",
    "    intersection = K.sum(intersection, axis=axis)\n",
    "    y_true = K.sum(y_true, axis=axis)\n",
    "    y_pred = K.sum(y_pred, axis=axis)\n",
    "\n",
    "    # Calculate Soft Dice Similarity Coefficient\n",
    "    dice = ((2 * intersection) + smooth) / (y_true + y_pred + smooth)\n",
    "\n",
    "    # Obtain mean of Dice & return result score\n",
    "    dice = K.mean(dice)\n",
    "    return dice\n",
    "    \n",
    "#-----------------------------------------------------#\n",
    "#                    Tversky loss                     #\n",
    "#-----------------------------------------------------#\n",
    "#                     Reference:                      #\n",
    "#                Sadegh et al. (2017)                 #\n",
    "#     Tversky loss function for image segmentation    #\n",
    "#      using 3D fully convolutional deep networks     #\n",
    "#-----------------------------------------------------#\n",
    "# alpha=beta=0.5 : dice coefficient                   #\n",
    "# alpha=beta=1   : jaccard                            #\n",
    "# alpha+beta=1   : produces set of F*-scores          #\n",
    "#-----------------------------------------------------#\n",
    "def tversky_class(y_true, y_pred, smooth=0.000001):\n",
    "     # Define alpha and beta\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    # Calculate Tversky for each class\n",
    "    axis = identify_axis(y_true.get_shape())\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = K.sum(y_true * y_pred, axis=axis)\n",
    "    fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "    fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "    tversky_class = (tp + smooth)/(tp + alpha*fn + beta*fp + smooth)\n",
    "\n",
    "    return tversky_class\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=0.000001):\n",
    "    # Sum up classes to one score\n",
    "    tversky = K.mean(tversky_class(y_true, y_pred, smooth))\n",
    "    # Return Tversky\n",
    "    return tversky\n",
    "\n",
    "def tversky_loss(y_true, y_pred, smooth=0.000001):\n",
    "    # Sum up classes to one score\n",
    "    tversky = K.sum(tversky_class(y_true, y_pred, smooth), axis=[-1])\n",
    "    # Identify number of classes\n",
    "    n = K.cast(K.shape(y_true)[-1], 'float32')\n",
    "    # Return Tversky\n",
    "    return n-tversky\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#             Tversky & Crossentropy loss             #\n",
    "#-----------------------------------------------------#\n",
    "def tversky_crossentropy(y_truth, y_pred):\n",
    "    # Obtain Tversky Loss\n",
    "    tversky = focal_tversky_loss(y_truth, y_pred)\n",
    "    # Obtain Crossentropy\n",
    "    crossentropy = K.binary_crossentropy(y_truth, y_pred)\n",
    "    crossentropy = K.mean(crossentropy)\n",
    "    # Return sum\n",
    "    return tversky + crossentropy\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, delta=0.7, gamma=0.75, smooth=0.000001):\n",
    "    # Clip values to prevent division by zero error\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    axis = identify_axis(y_true.get_shape())\n",
    "    # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "    tp = K.sum(y_true * y_pred, axis=axis)\n",
    "    fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "    fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "    tversky_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "    # Average class scores\n",
    "    return K.mean(K.pow((1-tversky_class), gamma))\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "#                     Subroutines                     #\n",
    "#-----------------------------------------------------#\n",
    "# Identify shape of tensor and return correct axes\n",
    "def identify_axis(shape):\n",
    "    if len(shape) == 5 : return [1,2,3]\n",
    "    elif len(shape) == 4 : return [1,2]\n",
    "    # Exception - Unknown\n",
    "    else:\n",
    "        print(shape) \n",
    "        raise ValueError('Metric: Shape of tensor is neither 2D or 3D.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class Plain:\n",
    "    #---------------------------------------------#\n",
    "    #                Initialization               #\n",
    "    #---------------------------------------------#\n",
    "    def __init__(self, activation='sigmoid', conv_layer_activation='lrelu',\n",
    "                 batch_normalization=True, batch_normalization_params=None,\n",
    "                 dropout=0, pooling=(1, 2, 2)):\n",
    "        # Parse parameter\n",
    "        if batch_normalization_params is None:\n",
    "            batch_normalization_params = {'epsilon': 1e-5}\n",
    "        self.activation = activation\n",
    "        # Parse activation layer\n",
    "        if conv_layer_activation == \"lrelu\":\n",
    "            self.conv_layer_activation = LeakyReLU(alpha=0.1)\n",
    "        # Batch normalization settings\n",
    "        self.ba_norm = batch_normalization\n",
    "        self.ba_norm_params = batch_normalization_params\n",
    "        # Dropout params\n",
    "        self.dropout = dropout\n",
    "        # Adjust pooling step\n",
    "        self.pooling = pooling\n",
    "        # Create list of filters\n",
    "        self.feature_map = [30, 60, 120, 240, 320]\n",
    "        \n",
    "    def create_model(self, n_labels):\n",
    "        # Input layer\n",
    "        inputs = Input(img_size + [outer_dim])\n",
    "        # Start the CNN Model chain with adding the inputs as first tensor\n",
    "        cnn_chain = inputs\n",
    "        # Cache contracting normalized conv layers\n",
    "        # for later copy & concatenate links\n",
    "        contracting_convs = []\n",
    "\n",
    "        # Contracting layers\n",
    "        for i in range(0, len(self.feature_map)):\n",
    "            neurons = self.feature_map[i]\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "            contracting_convs.append(cnn_chain)\n",
    "            cnn_chain = MaxPooling2D(pool_size=(2, 2))(cnn_chain)\n",
    "\n",
    "        # Middle Layer\n",
    "        neurons = self.feature_map[-1]\n",
    "        cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                  self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "        cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                  self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "\n",
    "        # Expanding Layers\n",
    "        for i in reversed(range(0, len(self.feature_map))):\n",
    "            neurons = self.feature_map[i]\n",
    "            cnn_chain = Conv2DTranspose(neurons, (2, 2), strides=(2, 2),\n",
    "                                        padding='same')(cnn_chain)\n",
    "            cnn_chain = concatenate([cnn_chain, contracting_convs[i]], axis=-1)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "            cnn_chain = conv_layer_2D(cnn_chain, neurons, self.conv_layer_activation,\n",
    "                                      self.ba_norm, self.ba_norm_params, self.dropout, strides=1)\n",
    "\n",
    "        # Output Layer\n",
    "        conv_out = Conv2D(n_labels, (1, 1), activation=self.activation)(cnn_chain)\n",
    "        # Create Model with associated input and output layers\n",
    "        model = Model(inputs=[inputs], outputs=[conv_out])\n",
    "        # Return model\n",
    "        return model\n",
    "\n",
    "# ----------------------------------------------------#\n",
    "#                   Subroutines 2D                    #\n",
    "# ----------------------------------------------------#\n",
    "# Convolution layer\n",
    "def conv_layer_2D(input, neurons, activation, ba_norm, ba_params, dropout, strides=1):\n",
    "    conv = Conv2D(neurons, (3, 3), padding='same', strides=strides)(input)\n",
    "\n",
    "    if dropout:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "    if ba_norm:\n",
    "        conv = tfa.layers.InstanceNormalization(**ba_params)(conv)\n",
    "\n",
    "    return activation(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e252e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Plain().create_model(num_classes)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=5e-4)\n",
    "model.compile(loss=tversky_crossentropy, optimizer=optimizer, metrics=[dice_soft])\n",
    "\n",
    "latest_checkpoint = tf.train.latest_checkpoint(\"C:\\\\Users\\\\Students\\\\Desktop\\\\Endometriosis\\\\Notebooks\\\\glenda_model\")\n",
    "model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=10) # controls default text sizes\n",
    "\n",
    "def visualize_detections(image, boxes, classes, title, figsize=(17, 17), linewidth=1, color=[1, 1, 1]):\n",
    "    \"\"\"Visualize Detections\"\"\"\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    for box, _cls in zip(boxes, classes):\n",
    "        _cls_parts = _cls.split('.')\n",
    "        text = f\"{_cls_parts[0][:2].lower()}.{_cls_parts[1][:3].lower()}\"\n",
    "        \n",
    "        y1, x1, y2, x2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        \n",
    "        patch = plt.Rectangle(\n",
    "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "        ax.text(\n",
    "            (x1 + x2) // 2,\n",
    "            y2 - 10,\n",
    "            text,\n",
    "            bbox={\"facecolor\": color, \"alpha\": 0.4},\n",
    "            clip_box=ax.clipbox,\n",
    "            clip_on=True,\n",
    "        )\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "def dice_soft_np(y_true, y_pred, smooth=0.00001):\n",
    "    axis = (0, 1)\n",
    "\n",
    "    # Calculate required variables\n",
    "    intersection = np.multiply(y_true, y_pred)\n",
    "    intersection = np.sum(intersection, axis=axis)\n",
    "    y_true = np.sum(y_true, axis=axis)\n",
    "    y_pred = np.sum(y_pred, axis=axis)\n",
    "\n",
    "    # Calculate Soft Dice Similarity Coefficient\n",
    "    dice = np.divide((2 * intersection) + smooth, y_true + y_pred + smooth)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66d2a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cat_names = ['Adhesions.Dense', 'Adhesions.Filmy', 'Deep.Endometriosis', 'Ovarian.Chocolate Fluid', \n",
    "             'Ovarian.Endometrioma', 'Superficial.Black', 'Superficial.Red', 'Superficial.Subtle', \n",
    "             'Superficial.White', 'Background']\n",
    "\n",
    "all_dice_scores = []\n",
    "all_y_true, all_y_pred = [], []\n",
    "\n",
    "for k, sample in enumerate(val_dataset_raw):\n",
    "    img_data_orig = sample['image']\n",
    "    seg_data_orig = sample['segmentation']\n",
    "    \n",
    "    seg_data = tf.cast(seg_data_orig, dtype=tf.float32)\n",
    "    img_data = tf.cast(img_data_orig, dtype=tf.float32)\n",
    "    img_data = tf.image.resize(img_data, img_size)\n",
    "    seg_data = tf.image.resize(seg_data, img_size)\n",
    "\n",
    "    neg_updates = tf.tile([0], [tf.reduce_sum(tf.cast(seg_data < 0.5, dtype=tf.int32))])\n",
    "    pos_updates = tf.tile([1], [tf.reduce_sum(tf.cast(seg_data >= 0.5, dtype=tf.int32))])\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data >= 0.5), tf.cast(pos_updates, dtype=tf.float32))\n",
    "    seg_data = tf.tensor_scatter_nd_update(seg_data, tf.where(seg_data < 0.5), tf.cast(neg_updates, dtype=tf.float32))\n",
    "        \n",
    "    pred_data = model.predict(normalize_with_moments(tf.expand_dims(img_data, 0)))\n",
    "    prediction = np.where(pred_data > 0.9, 1, 0)[0]\n",
    "    \n",
    "    y_true = tf.reduce_max(seg_data, axis=[0,1]).numpy().astype(int)\n",
    "    y_pred = np.zeros((num_classes,), dtype=int)\n",
    "    \n",
    "    all_dice_scores.append(dice_soft_np(seg_data.numpy(), prediction))\n",
    "    all_y_true.append(y_true)\n",
    "    all_y_pred.append(y_pred)\n",
    "    \n",
    "    prediction_classes, prediction_boxes = [], []\n",
    "    gt_classes, gt_boxes = [], []\n",
    "    \n",
    "    for i in range(num_classes-1):\n",
    "        ground_truth = label(seg_data_orig[...,i])\n",
    "        prediction_cls = label(prediction[...,i]) \n",
    "        props_prediction = [p for p  in regionprops(prediction_cls) if p.area > 100]\n",
    "        props_gt = [p for p in regionprops(ground_truth)]\n",
    "        \n",
    "        prediction_boxes.extend([p.bbox for p in props_prediction])\n",
    "        gt_boxes.extend([p.bbox for p in props_gt])\n",
    "        \n",
    "        prediction_classes.extend([cat_names[i]] * len(props_prediction))\n",
    "        gt_classes.extend([cat_names[i]] * len(props_gt))\n",
    "        \n",
    "        if prediction_boxes:\n",
    "            y_pred[i] = 1\n",
    "    \n",
    "    if k < 100:\n",
    "        visualize_detections(img_data_orig, gt_boxes, gt_classes, \"Ground Thruth\")\n",
    "        visualize_detections(img_data, prediction_boxes, prediction_classes, \"Model Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete DSC\")\n",
    "print(list(zip(cat_names, np.array(all_dice_scores).mean(axis=0))))\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(classification_report(np.array(all_y_true), np.array(all_y_pred), target_names=cat_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "############################################################\n",
    "#  COCO Evaluation\n",
    "############################################################\n",
    "def evaluate_coco(model, dataset, coco, eval_type=\"bbox\"):\n",
    "    results, coco_image_ids = [], []\n",
    "    \n",
    "    for sample in tqdm(dataset):\n",
    "        img_id = sample[\"id\"].numpy().decode('utf-8')\n",
    "        img_data_orig = sample['image']\n",
    "        seg_data_orig = sample['segmentation']\n",
    "        img_data_orig_shape = tf.shape(img_data_orig).numpy()\n",
    "\n",
    "        seg_data = tf.cast(seg_data_orig, dtype=tf.float32)\n",
    "        img_data = tf.cast(img_data_orig, dtype=tf.float32)\n",
    "        img_data = tf.image.resize(img_data, img_size)\n",
    "        seg_data = tf.image.resize(seg_data, img_size)\n",
    "\n",
    "        pred_data = model.predict(normalize_with_moments(tf.expand_dims(img_data, 0)))\n",
    "        prediction = np.where(pred_data > 0.9, 1, 0)[0]\n",
    "        prediction_classes, prediction_boxes = [], []\n",
    "\n",
    "        for i in range(num_classes-1):\n",
    "            prediction_cls = label(prediction[...,i]) \n",
    "            props_prediction = [p for p  in regionprops(prediction_cls) if p.area > 100]\n",
    "            props_gt = [p for p in regionprops(ground_truth)]\n",
    "\n",
    "            prediction_boxes.extend([p.bbox for p in props_prediction])\n",
    "            prediction_classes.extend([i * len(props_prediction)])        \n",
    "        \n",
    "        ratio = (img_size[0] / img_data_orig_shape[0], img_size[1] / img_data_orig_shape[1])\n",
    "        coco_image_ids.append(img_id)\n",
    "        \n",
    "        for _cls, bbox in zip(prediction_classes, prediction_boxes):\n",
    "            y1, x1, y2, x2 = bbox\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "                                       \n",
    "            results.append({\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": _cls,\n",
    "                \"bbox\": [int(x1 / ratio[1]), int(y1 / ratio[0]), int(w / ratio[1]), int(h / ratio[0])],\n",
    "                \"score\": 1.0\n",
    "            })\n",
    "\n",
    "    # Load results. This modifies results with additional attributes.\n",
    "    coco_results = coco.loadRes(results)\n",
    "\n",
    "    # Evaluate\n",
    "    cocoEval = COCOeval(coco, coco_results, eval_type)\n",
    "    cocoEval.params.imgIds = coco_image_ids\n",
    "    cocoEval.params.iouThrs = np.linspace(.1, 0.95, int(np.round((0.95 - .1) / .05)) + 1, endpoint=True)\n",
    "    cocoEval.params.maxDets = [1, 2, 5]\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    \n",
    "    return cocoEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f64e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_common = \"C:\\\\Users\\\\Students\\\\Desktop\\\\Endometriosis\\\\Datasets\"\n",
    "\n",
    "coco_path = os.path.join(path_common, 'glenda_coco2', 'glenda_full_v3.json')\n",
    "coco_annotation = COCO(annotation_file=coco_path)\n",
    "\n",
    "coco_eval = evaluate_coco(model, val_dataset_raw, coco_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe12fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
